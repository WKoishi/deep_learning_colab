{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xception.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1PLCtEJrHyAOSOK93bGsEz3uVhEtK8SZ7",
      "authorship_tag": "ABX9TyMCd8G/uGc282+QFrxZHM7N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WKoishi/deep_learning_colab/blob/main/xception.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K255qkFofe4"
      },
      "source": [
        "### 查看当前GPU信息"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM8jUpgE1-PD"
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueM-eBpGojY6"
      },
      "source": [
        "### 解压在本地整理好并上传的数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31zJw_cS5QId"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "\n",
        "!unzip dataset_face_shuffle.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aYffBaHozcP"
      },
      "source": [
        "### 神经网络的搭建和训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EELL8BZBKme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa05454a-8873-4c9f-d68d-1f8b2e2de8d9"
      },
      "source": [
        "import os, datetime\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.xception import preprocess_input\n",
        "from tensorflow.keras import callbacks\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "logdir = os.path.join(\"my_train_log\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "callbacks_list = [   \n",
        "    # callbacks.ModelCheckpoint(   \n",
        "    #     filepath='my_model.h5',   \n",
        "    #     monitor='val_loss',   \n",
        "    #     save_best_only=True, \n",
        "    # ), \n",
        "    callbacks.TensorBoard(\n",
        "        log_dir = logdir,\n",
        "    )\n",
        "]\n",
        "\n",
        "# 设置GPU显存\n",
        "config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
        "#config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
        "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))\n",
        "\n",
        "img_shape = (128, 128)\n",
        "train_dir = 'dataset_face_shuffle/train'\n",
        "validation_dir = 'dataset_face_shuffle/validation'\n",
        "\n",
        "#将训练数据进行增强\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=30,  #图像随机旋转的角度范围\n",
        "    width_shift_range=0.1,  #图像在水平或垂直方向上平移的范围（相对于高度或宽度的比例）\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range = 0.1,  #随机缩放的范围\n",
        "    horizontal_flip=True,  #随机将一半图像水平翻转\n",
        "    vertical_flip=True,     #随机垂直翻转\n",
        "    fill_mode='nearest',  #填充新创建的像素\n",
        ")\n",
        "\n",
        "#将验证数据进行轻度的增强\n",
        "validation_datagen = ImageDataGenerator(\n",
        "    preprocessing_function = preprocess_input,\n",
        "    # rotation_range=20,\n",
        "    # vertical_flip=True,\n",
        "    # horizontal_flip=True\n",
        ")\n",
        "\n",
        "\n",
        "#使用Python生成器\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = img_shape, \n",
        "    batch_size = 32,  #每个批量中包含20个样本\n",
        "    class_mode ='categorical' \n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = img_shape, \n",
        "    batch_size = 16,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "\n",
        "base_model = Xception(input_shape=(128,128,3), include_top=False,\n",
        "                    weights='imagenet')\n",
        "\n",
        "x = base_model.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "\n",
        "predictions = layers.Dense(2, name='Logits')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# for i, layer in enumerate(model.layers):\n",
        "#    print(i, layer.trainable, layer.name)\n",
        "\n",
        "#print(model.summary())\n",
        "\n",
        "\n",
        "model.compile(optimizer = optimizers.Adam(learning_rate=0.0002),\n",
        "            loss = losses.CategoricalCrossentropy(from_logits=True),\n",
        "            metrics=['acc'])\n",
        "\n",
        "history=model.fit(train_generator,\n",
        "          steps_per_epoch=92,\n",
        "          epochs=35,\n",
        "          validation_data=validation_generator,\n",
        "          validation_steps=46,\n",
        "          callbacks=callbacks_list)\n",
        "\n",
        "#get_tf_model_proto(model)  #保存成pb文件\n",
        "model.save('FR_classify_1.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Found 2950 images belonging to 2 classes.\n",
            "Found 736 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/35\n",
            "92/92 [==============================] - 47s 450ms/step - loss: 0.5791 - acc: 0.7025 - val_loss: 0.4494 - val_acc: 0.7840\n",
            "Epoch 2/35\n",
            "92/92 [==============================] - 40s 435ms/step - loss: 0.4399 - acc: 0.8067 - val_loss: 0.4364 - val_acc: 0.8152\n",
            "Epoch 3/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.3950 - acc: 0.8232 - val_loss: 0.3958 - val_acc: 0.8342\n",
            "Epoch 4/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.3522 - acc: 0.8557 - val_loss: 0.3924 - val_acc: 0.8302\n",
            "Epoch 5/35\n",
            "92/92 [==============================] - 40s 433ms/step - loss: 0.3330 - acc: 0.8588 - val_loss: 0.4206 - val_acc: 0.8261\n",
            "Epoch 6/35\n",
            "92/92 [==============================] - 40s 433ms/step - loss: 0.3117 - acc: 0.8735 - val_loss: 0.5515 - val_acc: 0.8043\n",
            "Epoch 7/35\n",
            "92/92 [==============================] - 40s 435ms/step - loss: 0.2948 - acc: 0.8787 - val_loss: 0.3534 - val_acc: 0.8492\n",
            "Epoch 8/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.2853 - acc: 0.8811 - val_loss: 0.5013 - val_acc: 0.8207\n",
            "Epoch 9/35\n",
            "92/92 [==============================] - 40s 433ms/step - loss: 0.2776 - acc: 0.8825 - val_loss: 0.4519 - val_acc: 0.8410\n",
            "Epoch 10/35\n",
            "92/92 [==============================] - 40s 434ms/step - loss: 0.2589 - acc: 0.8958 - val_loss: 0.3587 - val_acc: 0.8641\n",
            "Epoch 11/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.2370 - acc: 0.8989 - val_loss: 0.3542 - val_acc: 0.8791\n",
            "Epoch 12/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.2334 - acc: 0.9039 - val_loss: 0.3347 - val_acc: 0.8614\n",
            "Epoch 13/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.2334 - acc: 0.9003 - val_loss: 0.4207 - val_acc: 0.8723\n",
            "Epoch 14/35\n",
            "92/92 [==============================] - 40s 434ms/step - loss: 0.2289 - acc: 0.9047 - val_loss: 0.3268 - val_acc: 0.8696\n",
            "Epoch 15/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.2290 - acc: 0.9109 - val_loss: 0.3667 - val_acc: 0.8668\n",
            "Epoch 16/35\n",
            "92/92 [==============================] - 40s 430ms/step - loss: 0.2269 - acc: 0.9013 - val_loss: 0.5875 - val_acc: 0.8424\n",
            "Epoch 17/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.2117 - acc: 0.9116 - val_loss: 0.5531 - val_acc: 0.7908\n",
            "Epoch 18/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.1978 - acc: 0.9167 - val_loss: 0.3997 - val_acc: 0.8587\n",
            "Epoch 19/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.1901 - acc: 0.9246 - val_loss: 0.3728 - val_acc: 0.8750\n",
            "Epoch 20/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.1983 - acc: 0.9198 - val_loss: 0.3667 - val_acc: 0.8777\n",
            "Epoch 21/35\n",
            "92/92 [==============================] - 40s 433ms/step - loss: 0.1883 - acc: 0.9246 - val_loss: 0.4545 - val_acc: 0.8234\n",
            "Epoch 22/35\n",
            "92/92 [==============================] - 40s 434ms/step - loss: 0.1762 - acc: 0.9270 - val_loss: 0.4321 - val_acc: 0.8682\n",
            "Epoch 23/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.1589 - acc: 0.9366 - val_loss: 0.3953 - val_acc: 0.8641\n",
            "Epoch 24/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.1673 - acc: 0.9356 - val_loss: 0.3754 - val_acc: 0.8614\n",
            "Epoch 25/35\n",
            "92/92 [==============================] - 40s 433ms/step - loss: 0.1593 - acc: 0.9407 - val_loss: 0.4666 - val_acc: 0.8641\n",
            "Epoch 26/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.1564 - acc: 0.9411 - val_loss: 0.5474 - val_acc: 0.8668\n",
            "Epoch 27/35\n",
            "92/92 [==============================] - 40s 431ms/step - loss: 0.1543 - acc: 0.9387 - val_loss: 0.4668 - val_acc: 0.8736\n",
            "Epoch 28/35\n",
            "92/92 [==============================] - 40s 430ms/step - loss: 0.1531 - acc: 0.9448 - val_loss: 0.8075 - val_acc: 0.7785\n",
            "Epoch 29/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.1415 - acc: 0.9448 - val_loss: 0.4680 - val_acc: 0.8668\n",
            "Epoch 30/35\n",
            "92/92 [==============================] - 40s 433ms/step - loss: 0.1501 - acc: 0.9387 - val_loss: 0.3898 - val_acc: 0.8601\n",
            "Epoch 31/35\n",
            "92/92 [==============================] - 40s 430ms/step - loss: 0.1373 - acc: 0.9452 - val_loss: 0.4622 - val_acc: 0.8560\n",
            "Epoch 32/35\n",
            "92/92 [==============================] - 40s 430ms/step - loss: 0.1219 - acc: 0.9503 - val_loss: 0.3850 - val_acc: 0.8641\n",
            "Epoch 33/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.1339 - acc: 0.9544 - val_loss: 0.3971 - val_acc: 0.8478\n",
            "Epoch 34/35\n",
            "92/92 [==============================] - 40s 432ms/step - loss: 0.1584 - acc: 0.9363 - val_loss: 0.4200 - val_acc: 0.8560\n",
            "Epoch 35/35\n",
            "92/92 [==============================] - 40s 430ms/step - loss: 0.1289 - acc: 0.9537 - val_loss: 0.4324 - val_acc: 0.8682\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtH-9gbopHWu"
      },
      "source": [
        "### 打开tensorboard查看训练记录"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5F73BBSpQMf"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "%load_ext tensorboard\n",
        "#%reload_ext tensorboard\n",
        "%tensorboard --logdir my_train_log"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}